{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Curve fitting\n",
    "=============\n",
    "\n",
    "Curve fitting in ERLabPy largely relies on `lmfit <https://lmfit.github.io/lmfit-py/>`_.\n",
    "Along with some convenient models for common fitting tasks, ERLabPy provides a powerful\n",
    "accessor that streamlines curve fitting on multidimensional xarray objects.\n",
    "\n",
    "ERLabPy also provides optional integration of lmfit models with `iminuit\n",
    "<https://github.com/scikit-hep/iminuit>`_, which is a Python interface to the `Minuit\n",
    "C++ library <https://root.cern.ch/doc/master/Minuit2Page.html>`_ developed at CERN.\n",
    "\n",
    "In this tutorial, we will start with the basics of curve fitting using lmfit, introduce\n",
    "some models that are available in ERLabPy, and demonstrate curve fitting with the\n",
    ":meth:`modelfit <erlab.accessors.fit.ModelFitDataArrayAccessor.__call__>` accessor to\n",
    "fit multidimensional xarray objects. Finally, we will show how to use `iminuit\n",
    "<https://github.com/scikit-hep/iminuit>`_ with lmfit models.\n",
    "\n",
    "\n",
    "Curve fitting with ``lmfit``\n",
    "----------------------------\n",
    "\n",
    "In this section, we will cover basic curve fitting using `lmfit\n",
    "<https://lmfit.github.io/lmfit-py/>`_. If you are familiar with the library, you can\n",
    ":ref:`skip to the next section <pre-defined-models>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import erlab.plotting.erplot as eplt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from erlab.io.exampledata import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = [\"svg\", \"pdf\"]\n",
    "plt.rcParams[\"figure.dpi\"] = 96\n",
    "plt.rcParams[\"image.cmap\"] = \"viridis\"\n",
    "plt.rcParams[\"figure.figsize\"] = eplt.figwh(wscale=1.2, fixed_height=False)\n",
    "\n",
    "nb_execution_mode = \"cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a model function and the data to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly1(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "# Generate some toy data\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = poly1(x, 1, 2)\n",
    "\n",
    "# Add some noise with fixed seed for reproducibility\n",
    "rng = np.random.default_rng(1)\n",
    "yerr = np.full_like(x, 0.5)\n",
    "y = rng.normal(y, yerr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Fitting a simple function\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "A lmfit model can be created by calling :class:`lmfit.Model` class with the model\n",
    "function and the independent variable(s) as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "model = lmfit.Model(poly1)\n",
    "params = model.make_params(a=1.0, b=2.0)\n",
    "result = model.fit(y, x=x, params=params, weights=1 / yerr)\n",
    "\n",
    "result.plot()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing dictionaries to `make_params`, we can set the initial values of the parameters and also set the bounds for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lmfit.Model(poly1)\n",
    "params = model.make_params(\n",
    "    a={\"value\": 1.0, \"min\": 0.0},\n",
    "    b={\"value\": 2.0, \"vary\": False},\n",
    ")\n",
    "result = model.fit(y, x=x, params=params, weights=1 / yerr)\n",
    "_ = result.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "``result`` is a :class:`lmfit.model.ModelResult` object that contains the results of the\n",
    "fit. The best-fit parameters can be accessed through the ``result.params`` attribute.\n",
    "\n",
    ".. note ::\n",
    "\n",
    "    Since all weights are the same in this case, it has little effect on the fit\n",
    "    results. However, if we are confident that we have a good estimate of ``yerr``, we\n",
    "    can pass ``scale_covar=True`` to the ``fit`` method to obtain accurate\n",
    "    uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.params[\"a\"].value, result.params[\"a\"].stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters can also be retrieved in a form that allows easy error propagation calculation, enabled by the [uncertainties](https://github.com/lmfit/uncertainties) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_uvar = result.uvars[\"a\"]\n",
    "print(a_uvar)\n",
    "print(a_uvar**2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Fitting with composite models\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Before fitting, let us generate a Gaussian peak on a linear background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate toy data\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = -0.1 * x + 2 + 3 * np.exp(-((x - 5) ** 2) / (2 * 1**2))\n",
    "\n",
    "# Add some noise with fixed seed for reproducibility\n",
    "rng = np.random.default_rng(5)\n",
    "yerr = np.full_like(x, 0.3)\n",
    "y = rng.normal(y, yerr)\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(x, y, yerr, fmt=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A composite model can be created by adding multiple models together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import GaussianModel, LinearModel\n",
    "\n",
    "model = GaussianModel() + LinearModel()\n",
    "params = model.make_params(slope=-0.1, center=5.0, sigma={\"value\": 0.1, \"min\": 0})\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(y, x=x, params=params, weights=1 / yerr)\n",
    "result.plot()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about multiple gaussian peaks? Since the parameter names overlap between the models, we must use the `prefix` argument to distinguish between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianModel(prefix=\"p0_\") + GaussianModel(prefix=\"p1_\") + LinearModel()\n",
    "model.make_params()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "For more information, see the `lmfit documentation\n",
    "<https://lmfit.github.io/lmfit-py/fitting.html>`_.\n",
    "\n",
    ".. _pre-defined-models:\n",
    "\n",
    "Fitting with pre-defined models\n",
    "-------------------------------\n",
    "\n",
    "Creating composite models with different prefixes every time can be cumbersome, so\n",
    "ERLabPy provides some pre-defined models in :mod:`erlab.analysis.fit.models`.\n",
    "\n",
    "\n",
    "Fitting multiple peaks\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "One example is :class:`MultiPeakModel <erlab.analysis.fit.models.MultiPeakModel>`, which\n",
    "works like a composite model of multiple Gaussian or Lorentzian peaks.\n",
    "\n",
    "By supplying keyword arguments, you can specify the number of peaks, their shapes,\n",
    "whether to multiply with a Fermi-Dirac distribution, the shape of the background, and\n",
    "whether to convolve the result with experimental resolution.\n",
    "\n",
    "For a detailed explanation of all the arguments, see its :class:`documentation\n",
    "<erlab.analysis.fit.models.MultiPeakModel>`.\n",
    "\n",
    "The model can be constructed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erlab.analysis.fit.models import MultiPeakModel\n",
    "\n",
    "model = MultiPeakModel(npeaks=1, peak_shapes=[\"gaussian\"], fd=False, convolve=False)\n",
    "params = model.make_params(p0_center=5.0, p0_width=0.2, p0_height=3.0)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(y, x=x, params=params, weights=1 / yerr)\n",
    "_ = result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = result.eval_components()\n",
    "plt.errorbar(x, y, yerr, fmt=\"o\", zorder=-1, alpha=0.3)\n",
    "plt.plot(x, result.eval(), label=\"Best fit\")\n",
    "plt.plot(x, comps[\"1Peak_p0\"], \"--\", label=\"Peak\")\n",
    "plt.plot(x, comps[\"1Peak_bkg\"], \"--\", label=\"Background\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try fitting MDCs cut from simulated data with multiple Lorentzian peaks, convolved with a common instrumental resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data(bandshift=-0.2, count=5e8, seed=1).T\n",
    "cut = data.qsel(ky=0.3)\n",
    "cut.qplot(colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdc = cut.qsel(eV=0.0)\n",
    "mdc.qplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the model and set the initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erlab.analysis.fit.models import MultiPeakModel\n",
    "\n",
    "model = MultiPeakModel(npeaks=4, peak_shapes=[\"lorentzian\"], fd=False, convolve=True)\n",
    "\n",
    "params = model.make_params(\n",
    "    p0_center=-0.6,\n",
    "    p1_center=-0.45,\n",
    "    p2_center=0.45,\n",
    "    p3_center=0.6,\n",
    "    p0_width=0.02,\n",
    "    p1_width=0.02,\n",
    "    p2_width=0.02,\n",
    "    p3_width=0.02,\n",
    "    lin_bkg={\"value\": 0.0, \"vary\": False},\n",
    "    const_bkg=0.0,\n",
    "    resolution=0.03,\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can fit the model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(mdc, x=mdc.kx, params=params)\n",
    "result.plot()\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "Fitting ``xarray`` objects\n",
    "--------------------------\n",
    "\n",
    "ERLabPy provides accessors for xarray objects that allows you to fit data with lmfit\n",
    "models: :meth:`xarray.DataArray.modelfit\n",
    "<erlab.accessors.fit.ModelFitDataArrayAccessor.__call__>` or\n",
    ":meth:`xarray.Dataset.modelfit <erlab.accessors.fit.ModelFitDatasetAccessor.__call__>`,\n",
    "depending on whether you want to fit a single DataArray or multiple DataArrays in a\n",
    "Dataset. The accessor returns a :class:`xarray.Dataset` including the best-fit\n",
    "parameters and the fit statistics. The example below illustrates how to use the accessor\n",
    "to conduct the MDC fit demonstrated in the previous section.\n",
    "\n",
    ".. hint ::\n",
    "\n",
    "    The syntax of the accessors are similar to the xarray methods\n",
    "    :meth:`xarray.DataArray.curvefit` and :meth:`xarray.Dataset.curvefit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds = mdc.modelfit(\"kx\", model, params=params)\n",
    "result_ds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's take a closer look at data variables in the resulting Dataset.\n",
    "\n",
    "- ``modelfit_results`` contains the underlying :class:`lmfit.model.ModelResult` object from the fit.\n",
    "- ``modelfit_coefficients`` and ``modelfit_stderr`` contain the best-fit coefficients and their errors, respectively.\n",
    "- ``modelfit_stats`` contains the `goodness-of-fit statistics <https://lmfit.github.io/lmfit-py/fitting.html#goodness-of-fit-statistics>`_.\n",
    "\n",
    "It may not be immediately obvious how this is useful, but the true power of the accessor\n",
    "comes from its ability to utilize xarray's powerful broadcasting capabilities described\n",
    "in the next section.\n",
    "\n",
    "Fitting across multiple dimensions\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. note::\n",
    "\n",
    "    There is a dedicated module for Fermi edge fitting and correction, described\n",
    "    :ref:`here <fermi edge fitting>`. The following example is for illustrative purposes.\n",
    "\n",
    "Suppose you have to fit a single model to multiple data points across some dimension, or\n",
    "even multiple dimensions. The accessor can handle this with ease.\n",
    "\n",
    "Let's demonstrate this with a simulated cut that represents a curved Fermi edge at 100\n",
    "K, with an energy broadening of 20 meV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erlab.analysis.fit.models import FermiEdgeModel\n",
    "from erlab.io.exampledata import generate_gold_edge\n",
    "\n",
    "gold = generate_gold_edge(temp=100, Eres=0.02, count=5e5, seed=1)\n",
    "gold.qplot(cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select ± 0.2 eV around the Fermi level and fit the model across the energy\n",
    "axis for every EDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_selected = gold.sel(eV=slice(-0.2, 0.2))\n",
    "result_ds = gold_selected.modelfit(\n",
    "    \"eV\", FermiEdgeModel(), params={\"temp\": {\"value\": 100.0, \"vary\": False}}, guess=True\n",
    ")\n",
    "result_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the data variables in the resulting Dataset now depend on the coordinate\n",
    "`alpha`. Let's plot the center of the edge as a function of angle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.qplot(cmap=\"Greys\")\n",
    "plt.errorbar(\n",
    "    gold_selected.alpha,\n",
    "    result_ds.modelfit_coefficients.sel(param=\"center\"),\n",
    "    result_ds.modelfit_stderr.sel(param=\"center\"),\n",
    "    fmt=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Fitting is not limited to 1D models. The following example demonstrates a global fit to\n",
    "the cut with a multidimensional model. First, we normalize the data with the averaged\n",
    "intensity of each EDC and then fit the data to :class:`FermiEdge2dModel\n",
    "<erlab.analysis.fit.models.FermiEdge2dModel>`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erlab.analysis.fit.models import FermiEdge2dModel\n",
    "\n",
    "gold_norm = gold_selected / gold_selected.mean(\"eV\")\n",
    "result_ds = gold_norm.T.modelfit(\n",
    "    coords=[\"eV\", \"alpha\"],\n",
    "    model=FermiEdge2dModel(),\n",
    "    params={\"temp\": {\"value\": 100.0, \"vary\": False}},\n",
    "    guess=True,\n",
    ")\n",
    "result_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the fit results and the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = result_ds.modelfit_best_fit.transpose(*gold_norm.dims)\n",
    "\n",
    "fig, axs = eplt.plot_slices(\n",
    "    [gold_norm, best_fit, best_fit - gold_norm],\n",
    "    figsize=(4, 5),\n",
    "    cmap=[\"viridis\", \"viridis\", \"bwr\"],\n",
    "    norm=[plt.Normalize(), plt.Normalize(), eplt.CenteredPowerNorm(1.0, vcenter=0)],\n",
    "    colorbar=\"all\",\n",
    "    hide_colorbar_ticks=False,\n",
    "    colorbar_kw={\"width\": 7},\n",
    ")\n",
    "eplt.set_titles(axs, [\"Data\", \"FermiEdge2dModel\", \"Residuals\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Providing multiple initial guesses\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "You can also provide different initial guesses and bounds for different coordinates. To\n",
    "demonstrate, let's create some data containing multiple Gaussian peaks, each with a\n",
    "different center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define angle coordinates for 2D data\n",
    "alpha = np.linspace(-5.0, 5.0, 100)\n",
    "beta = np.linspace(-1.0, 1.0, 3)\n",
    "\n",
    "# Center of the peaks along beta\n",
    "center = np.array([-2.0, 0.0, 2.0])[:, np.newaxis]\n",
    "\n",
    "# Gaussian peak on a linear background\n",
    "y = -0.1 * alpha + 2 + 3 * np.exp(-((alpha - center) ** 2) / (2 * 1**2))\n",
    "\n",
    "# Add some noise with fixed seed for reproducibility\n",
    "rng = np.random.default_rng(5)\n",
    "yerr = np.full_like(y, 0.05)\n",
    "y = rng.normal(y, yerr)\n",
    "\n",
    "# Construct DataArray\n",
    "darr = xr.DataArray(y, dims=[\"beta\", \"alpha\"], coords={\"beta\": beta, \"alpha\": alpha})\n",
    "darr.qplot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "We can provide different initial guesses for the peak positions along the ``beta``\n",
    "dimension by passing a dictionary of DataArrays to the ``params`` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds = darr.modelfit(\n",
    "    coords=\"alpha\",\n",
    "    model=GaussianModel() + LinearModel(),\n",
    "    params={\n",
    "        \"center\": xr.DataArray([-2, 0, 2], coords=[darr.beta]),\n",
    "        \"slope\": -0.1,\n",
    "    },\n",
    ")\n",
    "result_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the fitted peak positions on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds.modelfit_data.qplot()\n",
    "result_center = result_ds.sel(param=\"center\")\n",
    "plt.plot(result_center.modelfit_coefficients, result_center.beta, \".-\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The same can be done with all parameter attributes that can be passed to\n",
    ":func:`lmfit.create_params` (e.g., ``vary``, ``min``, ``max``, etc.). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds = darr.modelfit(\n",
    "    coords=\"alpha\",\n",
    "    model=GaussianModel() + LinearModel(),\n",
    "    params={\n",
    "        \"center\": {\n",
    "            \"value\": xr.DataArray([-2, 0, 2], coords=[darr.beta]),\n",
    "            \"min\": -5.0,\n",
    "            \"max\": xr.DataArray([0, 2, 5], coords=[darr.beta]),\n",
    "        },\n",
    "        \"slope\": -0.1,\n",
    "    },\n",
    ")\n",
    "result_ds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Visualizing fits\n",
    "~~~~~~~~~~~~~~~~\n",
    "\n",
    "If `hvplot <https://github.com/holoviz/hvplot>`_ is installed, we can visualize the fit\n",
    "results interactively with the :class:`qshow\n",
    "<erlab.accessors.general.InteractiveDatasetAccessor>` accessor.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    If you are viewing this documentation online, the plot will not be interactive. Run the code locally to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds.qshow(plot_components=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Parallelization\n",
    "~~~~~~~~~~~~~~~\n",
    "\n",
    "The accessors are tightly integrated with `xarray`, so passing a dask array will\n",
    "parallelize the fitting process. See `Parallel Computing with Dask\n",
    "<https://docs.xarray.dev/en/stable/user-guide/dask.html>`_ for more information.\n",
    "\n",
    "For non-dask objects, you can achieve `joblib\n",
    "<https://joblib.readthedocs.io/en/stable/>`_-based parallelization:\n",
    "\n",
    "- For non-dask Datasets, basic parallelization across multiple data variables can be\n",
    "  achieved with the ``parallel`` argument to :meth:`xarray.Dataset.modelfit\n",
    "  <erlab.accessors.fit.ModelFitDatasetAccessor.__call__>`.\n",
    "\n",
    "- For parallelizing fits on a single DataArray along a dimension with many points, the\n",
    "  :meth:`xarray.DataArray.parallel_fit\n",
    "  <erlab.accessors.fit.ParallelFitDataArrayAccessor>` accessor can be used. This method\n",
    "  is similar to :meth:`xarray.DataArray.modelfit\n",
    "  <erlab.accessors.fit.ModelFitDataArrayAccessor.__call__>`, but requires the name of\n",
    "  the dimension to parallelize over instead of the coordinates to fit along. For\n",
    "  example, to parallelize the fit in the previous example, you can use the following\n",
    "  code:\n",
    "\n",
    "  .. code-block:: python\n",
    "\n",
    "      gold_selected.parallel_fit(\n",
    "          dim=\"alpha\",\n",
    "          model=FermiEdgeModel(),\n",
    "          params={\"temp\": {\"value\": 100.0, \"vary\": False}},\n",
    "          guess=True,\n",
    "      )\n",
    "\n",
    "  .. note ::\n",
    "  \n",
    "      - Note that the initial run will take a long time due to the overhead of creating\n",
    "        parallel workers. Subsequent calls will run faster, since joblib's default backend\n",
    "        will try to reuse the workers.\n",
    "      \n",
    "      - The accessor has some intrinsic overhead due to post-processing. If you need the\n",
    "        best performance, handle the parallelization yourself with joblib and\n",
    "        :meth:`lmfit.Model.fit <lmfit.model.Model.fit>`.\n",
    "\n",
    "Saving and loading fits\n",
    "~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Since the resulting dataset contains no Python objects, it can be saved and loaded\n",
    "reliably as a netCDF file using :meth:`xarray.Dataset.to_netcdf` and\n",
    ":func:`xarray.open_dataset`, respectively. If you wish to obtain the\n",
    ":class:`lmfit.model.ModelResult` objects from the fit, you can use the `output_result`\n",
    "argument.\n",
    "\n",
    ".. warning::\n",
    "\n",
    "    Saving full model results that includes the model functions can be difficult.\n",
    "    Instead of saving the fit results, it is recommended to save the code that can\n",
    "    reproduce the fit. See `the relevant lmfit documentation\n",
    "    <https://lmfit.github.io/lmfit-py/model.html#saving-and-loading-modelresults>`_ for\n",
    "    more information.\n",
    "\n",
    ".. _fermi edge fitting:\n",
    "\n",
    "Fermi edge fitting\n",
    "------------------\n",
    "\n",
    "Functions related to the Fermi edge are available in :mod:`erlab.analysis.gold`. To fit\n",
    "a polynomial to a Fermi edge, you can use :func:`erlab.analysis.gold.poly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from erlab.io.exampledata import generate_gold_edge\n",
    "\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import erlab.analysis as era\n",
    "import erlab.plotting.erplot as eplt\n",
    "\n",
    "gold = generate_gold_edge(temp=100, seed=1)\n",
    "result = era.gold.poly(\n",
    "    gold,\n",
    "    angle_range=(-15, 15),\n",
    "    eV_range=(-0.2, 0.2),\n",
    "    temp=100.0,\n",
    "    vary_temp=False,\n",
    "    degree=2,\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The resulting polynomial can be used to correct the Fermi edge with\n",
    ":func:`erlab.analysis.gold.correct_with_edge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era.gold.correct_with_edge(gold, result).qplot(cmap=\"Greys\")\n",
    "eplt.fermiline()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Also check out the interactive Fermi edge fitting tool,\n",
    ":func:`erlab.interactive.goldtool`.\n",
    "\n",
    "Using ``iminuit``\n",
    "-----------------\n",
    "\n",
    ".. note::\n",
    "\n",
    "    This part requires `iminuit <https://github.com/scikit-hep/iminuit>`_.\n",
    "\n",
    "`iminuit <https://github.com/scikit-hep/iminuit>`_ is a powerful Python interface to the\n",
    "`Minuit C++ library <https://root.cern.ch/doc/master/Minuit2Page.html>`_ developed at\n",
    "CERN. To learn more, see the `iminuit documentation <http://scikit-hep.org/iminuit/>`_.\n",
    "\n",
    "ERLabPy provides a thin wrapper around :class:`iminuit.Minuit` that allows you to use\n",
    "lmfit models with iminuit. The example below conducts the same fit as the previous one,\n",
    "but using iminuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erlab.analysis.fit.minuit import Minuit\n",
    "from erlab.analysis.fit.models import MultiPeakModel\n",
    "\n",
    "model = MultiPeakModel(npeaks=4, peak_shapes=[\"lorentzian\"], fd=False, convolve=True)\n",
    "\n",
    "m = Minuit.from_lmfit(\n",
    "    model,\n",
    "    mdc,\n",
    "    mdc.kx,\n",
    "    p0_center=-0.6,\n",
    "    p1_center=-0.45,\n",
    "    p2_center=0.45,\n",
    "    p3_center=0.6,\n",
    "    p0_width=0.02,\n",
    "    p1_width=0.02,\n",
    "    p2_width=0.02,\n",
    "    p3_width=0.02,\n",
    "    p0_height=1500,\n",
    "    p1_height=50,\n",
    "    p2_height=50,\n",
    "    p3_height=1500,\n",
    "    lin_bkg={\"value\": 0.0, \"vary\": False},\n",
    "    const_bkg=0.0,\n",
    "    resolution=0.03,\n",
    ")\n",
    "\n",
    "m.migrad()\n",
    "m.minos()\n",
    "m.hesse()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "You can also use the `interactive fitting interface\n",
    "<https://scikit-hep.org/iminuit/notebooks/interactive.html>`_ provided by iminuit.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    - Requires `ipywidgets <https://github.com/jupyter-widgets/ipywidgets>`_ to be\n",
    "      installed.\n",
    "    \n",
    "    - If you are viewing this documentation online, changing the sliders won’t change\n",
    "      the plot. run the code locally to try it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "m.interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
