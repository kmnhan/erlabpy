{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading & writing data\n",
    "======================"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. note::\n",
    "\n",
    "    If you are not familiar with :mod:`xarray`, it is recommended to read the `xarray\n",
    "    tutorial <https://tutorial.xarray.dev/>`_ and the `xarray user guide\n",
    "    <https://docs.xarray.dev/en/stable/user-guide/index.html>`_ first.\n",
    "\n",
    "In ERLabPy, data are represented as :class:`xarray.DataArray`, :class:`xarray.Dataset`,\n",
    "and :class:`xarray.DataTree` objects.\n",
    "\n",
    "- :class:`xarray.DataArray` are similar to waves in Igor Pro, but are much more flexible.\n",
    "  Opposed to the maximum of 4 dimensions in Igor, :class:`xarray.DataArray` can have as\n",
    "  many dimensions as you want (up to 64). Another advantage is that the coordinates of\n",
    "  the dimensions do not have to be evenly spaced. In fact, they are not limited to\n",
    "  numbers but can be any type of data, such as date and time representations.\n",
    "\n",
    "- :class:`xarray.Dataset` is a collection of :class:`xarray.DataArray` objects. It is\n",
    "  used to store multiple data arrays that are related to each other, such as a set of\n",
    "  measurements.\n",
    "\n",
    "- :class:`xarray.DataTree` is a hierarchical data structure that can store multiple\n",
    "  :class:`xarray.Dataset` objects, just like an Igor experiment file with multiple waves\n",
    "  within nested folders.\n",
    "\n",
    "See `Data Structures\n",
    "<https://docs.xarray.dev/en/latest/user-guide/data-structures.html>`_ in the xarray\n",
    "documentation for more information.\n",
    "\n",
    "This guide will introduce you to reading and writing data from and to various file\n",
    "formats, and how to implement a custom plugin for a experimental setup.\n",
    "\n",
    "Skip to the `corresponding section <#Loading-ARPES-data>`_ for guides on loading ARPES\n",
    "data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data\n",
    "------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ":mod:`xarray` provides basic support for reading and writing NetCDF and HDF5 files into\n",
    ":mod:`xarray` objects. See the :mod:`xarray` documentation on `I/O operations\n",
    "<https://docs.xarray.dev/en/stable/user-guide/io.html>`_ for more information.\n",
    "\n",
    "Here, we will focus on working with data exported from Igor Pro and some other commonly\n",
    "used file formats."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "From Igor Pro\n",
    "~~~~~~~~~~~~~\n",
    "\n",
    "Installing ERLabPy automatically registers a backend for xarray that allows reading\n",
    "``.pxt``, ``.pxp``, and ``.ibw`` files. This means that you can load these files\n",
    "directly into xarray using :func:`xarray.open_dataset` or :func:`xarray.open_dataarray`\n",
    "as if they were NetCDF files.\n",
    "\n",
    "In most cases, xarray will automatically detect the file format. For example, to load a\n",
    "``.ibw`` file into a :class:`xarray.DataArray`, use the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import xarray as xr\n",
    "\n",
    "data = xr.open_dataarray(\"path/to/wave.ibw\")\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Loading an experiment file to a :class:`xarray.DataTree` is also possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data = xr.open_datatree(\"path/to/experiment.pxpt\")\n",
    "```\n",
    "\n",
    "Along with the Igor Pro file formats, the backend also supports loading HDF5 files\n",
    "exported from Igor Pro. For such files, the engine must be specified explicitly with\n",
    "`engine=\"erlab-igor\"`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. warning::\n",
    "\n",
    "   Loading waves from complex ``.pxp`` files may fail or produce unexpected results. It\n",
    "   is recommended to export the waves to a ``.ibw`` file to load them in ERLabPy. If you\n",
    "   encounter any problems, please let us know by opening an issue.\n",
    "\n",
    "Convenience functions that can load Igor Pro files directly are implemented in\n",
    ":mod:`erlab.io.igor`, but it is recommended to use the xarray functions presented above.\n",
    "\n",
    "From arbitrary formats\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "There are many python libraries that can read and write data in various formats. Here,\n",
    "some common file formats and how to read them are listed:\n",
    "\n",
    "* Spreadsheet data can be read using :func:`pandas.read_csv` and\n",
    "  :func:`pandas.read_excel`.\n",
    "  \n",
    "  The resulting DataFrame can be converted to an xarray object using\n",
    "  :meth:`pandas.DataFrame.to_xarray` or :meth:`xarray.Dataset.from_dataframe`.\n",
    "\n",
    "* When reading HDF5 files with arbitrary groups and metadata, you must first explore the \n",
    "  group structure using `h5netcdf <https://h5netcdf.org/>`_. More conveniently, you can\n",
    "  use :func:`xarray.open_groups` to inspect the group structure.\n",
    "\n",
    "* FITS files can be read with `astropy\n",
    "  <https://docs.astropy.org/en/stable/io/fits/index.html>`_. In the near future, ERLabPy\n",
    "  will provide a loader for FITS files.\n",
    "\n",
    "* For working with NeXus files, see :mod:`erlab.io.nexusutils`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data\n",
    "------------\n",
    "Since the state and variables of a Python interpreter are not saved, it is important to\n",
    "save your data in a format that can be easily read and written.\n",
    "\n",
    "While it is possible to save and load entire Python interpreter sessions using\n",
    "[pickle](https://docs.python.org/3/library/pickle.html) or the more versatile\n",
    "[dill](https://github.com/uqfoundation/dill), it is out of the scope of this guide.\n",
    "Instead, we recommend saving your data in a format that is easy to read and write, such\n",
    "as HDF5 or NetCDF. To save and load xarray objects to such formats, see the xarray\n",
    "documentation on [I/O operations](https://docs.xarray.dev/en/stable/user-guide/io.html)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "To Igor Pro\n",
    "~~~~~~~~~~~\n",
    "\n",
    "As an experimental feature, :func:`save_as_hdf5 <erlab.io.save_as_hdf5>` can save\n",
    "certain DataArrays in a format that is compatible with the Igor Pro HDF5 loader. An\n",
    "`accompanying Igor procedure\n",
    "<https://github.com/kmnhan/erlabpy/blob/main/PythonInterface.ipf>`_ is available in the\n",
    "repository. If loading in Igor Pro fails, try saving again with all attributes removed.\n",
    "\n",
    "Alternatively, `igorwriter <https://github.com/t-onoz/igorwriter>`_ can be used to write\n",
    "numpy arrays to ``.ibw`` and ``.itx`` files directly.\n",
    "\n",
    ".. _loading-arpes-data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ARPES data\n",
    "------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERLabPy's data loading framework consists of various plugins, or *loaders*, each\n",
    "designed to load data from a different beamline or laboratory. Each *loader* is a class\n",
    "that has a `load` method which takes a file path or sequence number and returns data.\n",
    "\n",
    "Let's see the list of loaders available by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "notebookRunGroups": {
     "groupValue": ""
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import erlab.io\n",
    "\n",
    "erlab.io.loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = [\"svg\", \"pdf\"]\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 96\n",
    "plt.rcParams[\"image.cmap\"] = \"viridis\"\n",
    "\n",
    "xr.set_options(display_expand_data=False)\n",
    "nb_execution_mode = \"cache\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "You can access each loader by its name or alias, both as an attribute or as an item. For\n",
    "example, to access the loader for the ALS beamline 4.0.3, you can use any of the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "erlab.io.loaders[\"merlin\"]\n",
    "erlab.io.loaders[\"bl403\"]\n",
    "erlab.io.loaders.merlin\n",
    "erlab.io.loaders.bl403"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Data loading is done by calling the :meth:`load <erlab.io.dataloader.LoaderBase.load>`\n",
    "method of the loader. It requires an ``identifier`` parameter, which can be a path to a\n",
    "file or a sequence number. It also accepts a ``data_dir`` parameter, which specifies the\n",
    "directory where the data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `identifier` is a sequence number, `data_dir` must be provided.\n",
    "\n",
    "- If `identifier` is a string and `data_dir` is provided, the path is constructed by\n",
    "  joining `data_dir` and `identifier`.\n",
    "\n",
    "- If `identifier` is a string and `data_dir` is not provided, `identifier` should be a\n",
    "  valid path to a file.\n",
    "\n",
    "Suppose we have data from the ALS beamline 4.0.3 stored as `/path/to/data/f_001.pxt`,\n",
    "`/path/to/data/f_002.pxt`, etc. To load `f_001.pxt`, all three of the following are\n",
    "valid:\n",
    "\n",
    "```python\n",
    "loader = erlab.io.loaders[\"merlin\"]\n",
    "\n",
    "loader.load(\"/path/to/data/f_001.pxt\")\n",
    "loader.load(\"f_001.pxt\", data_dir=\"/path/to/data\")\n",
    "loader.load(1, data_dir=\"/path/to/data\")\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Setting the default loader and data directory\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "In practice, a loader and a single directory will be used repeatedly in a session to\n",
    "load different data from the same experiment.\n",
    "\n",
    "Instead of explicitly specifying the loader and directory each time, a default loader\n",
    "and data directory can be set with :func:`erlab.io.set_loader` and\n",
    ":func:`erlab.io.set_data_dir`. All subsequent calls to the shortcut function\n",
    ":func:`erlab.io.load` will use the specified loader and data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "erlab.io.set_loader(\"merlin\")\n",
    "erlab.io.set_data_dir(\"/path/to/data\")\n",
    "data_1 = erlab.io.load(1)\n",
    "data_2 = erlab.io.load(2)\n",
    "```\n",
    "\n",
    "The loader and data directory can also be controlled with a context manager:\n",
    "\n",
    "```python\n",
    "with erlab.io.loader_context(\"merlin\", data_dir=\"/path/to/data\"):\n",
    "    data_1 = erlab.io.load(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Data across multiple files\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For setups like the ALS beamline 4.0.3, some scans are stored over multiple files like\n",
    "`f_003_S001.pxt`, `f_003_S002.pxt`, and so on. In this case, the loader will\n",
    "automatically concatenate all files in the same scan. For example, *all of the\n",
    "following* will return the same concatenated data:\n",
    "\n",
    "```python\n",
    "erlab.io.load(3)\n",
    "erlab.io.load(\"f_003_S001.pxt\")\n",
    "erlab.io.load(\"f_003_S002.pxt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "If you want to cherry-pick a single file, you can pass ``single=True`` to :meth:`load\n",
    "<erlab.io.dataloader.LoaderBase.load>`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "erlab.io.load(\"f_003_S001.pxt\", single=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want automatic concatenation to happen, you can suppress it with `combine=False`. The following code will return a list of DataArrays:\n",
    "```python\n",
    "erlab.io.load(3, combine=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Handling multiple data directories\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "If you call :func:`erlab.io.set_loader` or :func:`erlab.io.set_data_dir` multiple times,\n",
    "the last call will override the previous ones. While this is useful for changing the\n",
    "loader or data directory, it makes data loading *dependent on execution order*. This may\n",
    "lead to unexpected behavior in notebooks.\n",
    "\n",
    "If you plan to use multiple loaders or data directories in the same session, it is\n",
    "recommended to use the context manager :func:`erlab.io.loader_context`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with erlab.io.loader_context(\"merlin\", data_dir=\"/path/to/data\"):\n",
    "    data = erlab.io.load(identifier)\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "It may also be convenient to define functions that set the loader and data directory and\n",
    "call :func:`erlab.io.load` with the appropriate arguments.\n",
    "\n",
    "Summarizing data\n",
    "~~~~~~~~~~~~~~~~\n",
    "\n",
    "Some supported loaders can generate a :class:`pandas.DataFrame` containing an overview\n",
    "of the data in a given directory. The generated summary can be viewed as a table with\n",
    "the :meth:`summarize <erlab.io.dataloader.LoaderBase.summarize>` method.\n",
    "\n",
    "If ``ipywidgets`` is installed, an interactive widget is also displayed. This is useful\n",
    "for quickly skimming through the data.\n",
    "\n",
    "Just like :meth:`load <erlab.io.dataloader.LoaderBase.load>`, :meth:`summarize\n",
    "<erlab.io.dataloader.LoaderBase.summarize>` can also be accessed with the shortcut\n",
    "function :func:`erlab.io.summarize`. For example, to display a summary of the data\n",
    "available in the directory ``/path/to/data`` using the ``'merlin'`` loader:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "erlab.io.set_loader(\"merlin\")\n",
    "erlab.io.summarize(\"/path/to/data\")\n",
    "```\n",
    "If the path is not specified, the current data directory is used."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "To see what the generated summary looks like, see the :ref:`example below <summary\n",
    "example>`.\n",
    "\n",
    ".. note ::\n",
    "    If the :ref:`ImageTool manager <imagetool-manager-guide>` is running, the\n",
    "    a button to open the data in ImageTool is shown in the interactive summary.\n",
    "\n",
    ".. _implementing-plugins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a data loader plugin \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "It is easy to add new loaders to the framework. Any subclass of :class:`LoaderBase\n",
    "<erlab.io.dataloader.LoaderBase>` is automatically registered as a loader! However, for\n",
    "the loader to actually perform any useful work, it must implement some attributes and\n",
    "methods. Before we dive into the details, let's first understand the data loading flow.\n",
    "\n",
    "Data loading flow\n",
    "~~~~~~~~~~~~~~~~~\n",
    "\n",
    "ARPES data from a single experiment are usually stored in one folder, with files that\n",
    "look like ``file_0001.h5``, ``file_0002.h5``, etc. If the naming scheme does not deviate\n",
    "from this pattern, only two methods need to be implemented: :meth:`identify\n",
    "<erlab.io.dataloader.LoaderBase.identify>` and :meth:`load_single\n",
    "<erlab.io.dataloader.LoaderBase.load_single>`. The following flowchart shows the process\n",
    "of loading data from a single scan, given the path to the directory (``data_dir``) and\n",
    "the sequence number or file name (``identifier``):\n",
    "\n",
    ".. image:: ../images/flowchart_single.pdf\n",
    "   :align: center\n",
    "   \n",
    "Here, :meth:`identify <erlab.io.dataloader.LoaderBase.identify>` is given an integer\n",
    "sequence number(``identifier``) and the path to the data folder(``data_dir``), and\n",
    "returns the full path to the corresponding data file. \n",
    "\n",
    "The method :meth:`load_single <erlab.io.dataloader.LoaderBase.load_single>` is given a\n",
    "full path to a single data file and must return the data as an :class:`xarray.DataArray`\n",
    "or a :class:`xarray.Dataset`. If the data cannot be combined into a single object, the\n",
    "method can also return a list of :class:`xarray.DataArray` objects.\n",
    "\n",
    "If only all data formats were as simple as this! Unfortunately, there are some setups\n",
    "where data for a single scan is saved over multiple files. In this case, the files will\n",
    "look like ``file_0001_0001.h5``, ``file_0001_0002.h5``, etc. For these kinds of setups,\n",
    "an additional method :meth:`infer_index <erlab.io.dataloader.LoaderBase.infer_index>`\n",
    "must be implemented. The following flowchart shows the process of loading data from\n",
    "multiple files:\n",
    "\n",
    ".. image:: ../images/flowchart_multiple.pdf\n",
    "   :align: center\n",
    "\n",
    "In this case, the method :meth:`identify <erlab.io.dataloader.LoaderBase.identify>`\n",
    "should resolve *all* files that belong to the given sequence number, and return a list\n",
    "of file paths along with a dictionary of corresponding coordinates.\n",
    "\n",
    "The method :meth:`infer_index <erlab.io.dataloader.LoaderBase.infer_index>` is given a\n",
    "bare file name (without the extension and path) and must return the sequence number of\n",
    "the scan. For example, given the file name ``file_0003_0123``, the method should return\n",
    "``3``.\n",
    "\n",
    "Conventions\n",
    "~~~~~~~~~~~\n",
    "\n",
    "There are some rules that loaded ARPES data must follow to ensure that analysis\n",
    "procedures such as momentum conversion and fermi edge fitting works seamlessly:\n",
    "\n",
    "- The experimental geometry should be stored in the ``'configuration'`` attribute as an\n",
    "  integer. See :ref:`Nomenclature <nomenclature>` and :class:`AxesConfiguration\n",
    "  <erlab.constants.AxesConfiguration>` for more information.\n",
    "\n",
    "- All standard angle coordinates must follow the naming conventions in\n",
    "  :ref:`Nomenclature <nomenclature>`.\n",
    "\n",
    "- The sample temperature, if available, should be stored in an attribute or coordinate\n",
    "  named ``'sample_temp'``.\n",
    "\n",
    "- The sample work function, if available, should be stored in an attribute named\n",
    "  ``'sample_workfunction'``.\n",
    "\n",
    "- The angular resolution of the analyzer, if available, should be stored in an attribute\n",
    "  named ``'angle_resolution'``. This is used in estimating momentum grid sizes when\n",
    "  converting to momentum space.\n",
    "\n",
    "\n",
    "In addition, use the following units:\n",
    "- Energies should be given in electronvolts.\n",
    "\n",
    "- Angles should be given in degrees.\n",
    "\n",
    "- Temperatures should be given in Kelvins.\n",
    "\n",
    "\n",
    "All loaders by default does a basic check for some of these rules using :meth:`validate\n",
    "<erlab.io.dataloader.LoaderBase.validate>` for every data file loaded. A warning is\n",
    "issued if some are missing. This behavior can be controlled with loader class attributes\n",
    ":attr:`skip_validate <erlab.io.dataloader.LoaderBase.skip_validate>` and\n",
    ":attr:`strict_validation <erlab.io.dataloader.LoaderBase.strict_validation>`.\n",
    "\n",
    "A minimal example\n",
    "~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Consider a setup that saves data into a ``.csv`` file named ``data_0001.csv``,\n",
    "``data_0002.csv``, and so on. A bare minimum implementation of a loader for the setup\n",
    "will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from erlab.io.dataloader import LoaderBase\n",
    "\n",
    "\n",
    "class MyLoader(LoaderBase):\n",
    "    name = \"my_loader\"\n",
    "    aliases = None\n",
    "    name_map = {}\n",
    "    coordinate_attrs = {}\n",
    "    additional_attrs = {\"information\": \"any metadata you want to load with the data\"}\n",
    "    skip_validate = False\n",
    "    always_single = True\n",
    "\n",
    "    def identify(self, num, data_dir):\n",
    "        file = os.path.join(data_dir, f\"data_{str(num).zfill(4)}.csv\")\n",
    "        return [file], {}\n",
    "\n",
    "    def load_single(self, file_path, without_values=False):\n",
    "        return pd.read_csv(file_path).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `without_values` argument to `load_single` is unused; it will be explained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "erlab.io.loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "erlab.io.loaders[\"my_loader\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "We can see that the loader has been registered.\n",
    "\n",
    "A complex example\n",
    "~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Next, let's try to write a more realistic loader for a hypothetical setup that saves\n",
    "data as HDF5 files with the following naming scheme: ``data_001.h5``, ``data_002.h5``,\n",
    "and so on, with multiple scans named like ``data_001_S001.h5``, ``data_001_S002.h5``,\n",
    "etc. with the scan axis information stored in a separate file named\n",
    "``data_001_axis.csv``.\n",
    "\n",
    "Let us first generate a data directory and place some synthetic data in it. Before\n",
    "saving, we rename and set some attributes that resemble real ARPES data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import erlab.io\n",
    "from erlab.io.exampledata import generate_data_angles\n",
    "\n",
    "\n",
    "def make_data(beta=5.0, temp=20.0, hv=50.0, bandshift=0.0):\n",
    "    data = generate_data_angles(\n",
    "        shape=(250, 1, 300),\n",
    "        angrange={\"alpha\": (-15, 15), \"beta\": (beta, beta)},\n",
    "        hv=hv,\n",
    "        configuration=1,\n",
    "        temp=temp,\n",
    "        bandshift=bandshift,\n",
    "        assign_attributes=False,\n",
    "        seed=1,\n",
    "    ).T\n",
    "\n",
    "    # Rename coordinates. The loader must rename them back to the original names.\n",
    "    data = data.rename(\n",
    "        {\n",
    "            \"alpha\": \"ThetaX\",\n",
    "            \"beta\": \"Polar\",\n",
    "            \"eV\": \"BindingEnergy\",\n",
    "            \"hv\": \"PhotonEnergy\",\n",
    "            \"xi\": \"Tilt\",\n",
    "            \"delta\": \"Azimuth\",\n",
    "        }\n",
    "    )\n",
    "    dt = datetime.datetime.now()\n",
    "\n",
    "    # Assign some attributes that real data would have\n",
    "    data = data.assign_attrs(\n",
    "        {\n",
    "            \"LensMode\": \"Angular30\",  # Lens mode of the analyzer\n",
    "            \"SpectrumType\": \"Fixed\",  # Acquisition mode of the analyzer\n",
    "            \"PassEnergy\": 10,  # Pass energy of the analyzer\n",
    "            \"UndPol\": 0,  # Undulator polarization\n",
    "            \"Date\": dt.strftime(r\"%d/%m/%Y\"),  # Date of the measurement\n",
    "            \"Time\": dt.strftime(\"%I:%M:%S %p\"),  # Time of the measurement\n",
    "            \"TB\": temp,\n",
    "            \"X\": 0.0,\n",
    "            \"Y\": 0.0,\n",
    "            \"Z\": 0.0,\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "# Create a temporary directory\n",
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Define coordinates for the scan\n",
    "beta_coords = np.linspace(2, 7, 10)\n",
    "\n",
    "# Generate and save cuts with different beta values\n",
    "for i, beta in enumerate(beta_coords):\n",
    "    data = make_data(beta=beta, temp=20.0, hv=50.0)\n",
    "    filename = f\"{tmp_dir.name}/data_001_S{str(i + 1).zfill(3)}.h5\"\n",
    "    data.to_netcdf(filename, engine=\"h5netcdf\")\n",
    "\n",
    "# Write scan coordinates to a csv file\n",
    "with open(f\"{tmp_dir.name}/data_001_axis.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Index\", \"Polar\"])\n",
    "\n",
    "    for i, beta in enumerate(beta_coords):\n",
    "        writer.writerow([i + 1, beta])\n",
    "\n",
    "# Generate some cuts with different band shifts\n",
    "for i in range(4):\n",
    "    data = make_data(beta=5.0, temp=20.0, hv=50.0, bandshift=-i * 0.05)\n",
    "    filename = f\"{tmp_dir.name}/data_{str(i + 2).zfill(3)}.h5\"\n",
    "    data.to_netcdf(filename, engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have generated a folder that resembles typical data from an ARPES experiment. Let's list the contents of the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(tmp_dir.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each HDF5 file represents a single ARPES cut. `data_001_S001.h5` to `data_001_S010.h5`\n",
    "represents an ARPES map with 10 cuts, with the scan axis recorded in\n",
    "`data_001_axis.csv`. Let's check what the raw data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.load_dataarray(f\"{tmp_dir.name}/data_002.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been properly loaded, but the coordinates and attributes have names that\n",
    "are specific to the beamline.\n",
    "\n",
    "Our loader should do three things: rename the coordinates and attributes to standard\n",
    "names, add metadata to the dataset, and combine related cuts into a single DataArray\n",
    "that contains the ARPES mapping."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. note ::\n",
    "\n",
    "    Here, we easily loaded the data into an xarray object directly, but that is not the\n",
    "    case for most experimental setups. Properly loading raw data into an xarray object\n",
    "    is a complex process that requires knowledge of the data format and the experimental\n",
    "    setup, and this is what must be implemented in the :meth:`load_single\n",
    "    <erlab.io.dataloader.LoaderBase.load_single>`.\n",
    "\n",
    "    ERLabPy provides convenient functions to ease this process. See `implementations of\n",
    "    existing data loaders\n",
    "    <https://github.com/kmnhan/erlabpy/tree/main/src/erlab/io/plugins>`_ for examples.\n",
    "\n",
    "Now that we have the data, let's implement the loader. The biggest difference from the\n",
    "previous example is that we need to handle multiple files for a single scan in\n",
    ":meth:`identify <erlab.io.dataloader.LoaderBase.identify>`. Also, we have to implement\n",
    ":meth:`infer_index <erlab.io.dataloader.LoaderBase.infer_index>` to extract the scan\n",
    "number from the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "from erlab.io.dataloader import LoaderBase\n",
    "from erlab.utils.misc import emit_user_level_warning\n",
    "\n",
    "\n",
    "class ExampleLoader(LoaderBase):\n",
    "    name = \"example\"\n",
    "\n",
    "    aliases = [\"Ex\"]\n",
    "\n",
    "    name_map = {\n",
    "        \"eV\": \"BindingEnergy\",\n",
    "        \"alpha\": \"ThetaX\",\n",
    "        \"beta\": [\n",
    "            \"Polar\",\n",
    "            \"Polar Compens\",\n",
    "        ],  # Can have multiple names assigned to the same name\n",
    "        # If both are present in the data, a ValueError will be raised\n",
    "        \"delta\": \"Azimuth\",\n",
    "        \"xi\": \"Tilt\",\n",
    "        \"x\": \"X\",\n",
    "        \"y\": \"Y\",\n",
    "        \"z\": \"Z\",\n",
    "        \"hv\": \"PhotonEnergy\",\n",
    "        \"polarization\": \"UndPol\",\n",
    "        \"sample_temp\": \"TB\",\n",
    "    }\n",
    "    # Map the names of the coordinates or attributes in the resulting data to the names\n",
    "    # present in the data returned by `load_single`. Note that the order of\n",
    "    # non-dimension coordinates in the output data will follow the order of the keys in\n",
    "    # this dictionary.\n",
    "\n",
    "    coordinate_attrs: tuple[str, ...] = (\n",
    "        \"beta\",\n",
    "        \"delta\",\n",
    "        \"xi\",\n",
    "        \"hv\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"polarization\",\n",
    "        \"photon_flux\",\n",
    "        \"sample_temp\",\n",
    "    )\n",
    "    # Attributes to be used as coordinates. Place all attributes that we don't want to\n",
    "    # lose when merging multiple file scans here.\n",
    "\n",
    "    additional_attrs = {\n",
    "        \"configuration\": 1,  # Experimental geometry. Required for momentum conversion\n",
    "        \"sample_workfunction\": 4.3,\n",
    "    }\n",
    "    # Any additional metadata you want to add to the data. Note that attributes defined\n",
    "    # here will not be transformed into coordinates. If you wish to promote some fixed\n",
    "    # attributes to coordinates, add them to additional_coords.\n",
    "\n",
    "    additional_coords = {}\n",
    "    # Additional non-dimension coordinates to be added to the data, for instance the\n",
    "    # photon energy for lab-based ARPES.\n",
    "\n",
    "    always_single = False\n",
    "\n",
    "    def identify(self, num, data_dir):\n",
    "        data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "        coord_dict = {}\n",
    "\n",
    "        # Look for scans with data_###_S###.h5, and sort them\n",
    "        files = sorted(data_dir.glob(f\"data_{str(num).zfill(3)}_S*.h5\"))\n",
    "\n",
    "        if len(files) == 0:\n",
    "            # If no files found, look for data_###.h5\n",
    "            files = sorted(data_dir.glob(f\"data_{str(num).zfill(3)}.h5\"))\n",
    "            if len(files) > 1:\n",
    "                # More than one file found with the same scan number, show warning\n",
    "                emit_user_level_warning(\n",
    "                    f\"Multiple files found for scan {num}, using {files[0]}\"\n",
    "                )\n",
    "                files = files[:1]\n",
    "        else:\n",
    "            # If files found, extract coordinate values from the filenames\n",
    "            axis_file = data_dir / f\"data_{str(num).zfill(3)}_axis.csv\"\n",
    "            with axis_file.open(\"r\") as f:\n",
    "                header = f.readline().strip().split(\",\")\n",
    "\n",
    "            # Load the coordinates from the csv file\n",
    "            coord_arr = np.loadtxt(axis_file, delimiter=\",\", skiprows=1)\n",
    "\n",
    "            # Each header entry will contain a dimension name\n",
    "            for i, hdr in enumerate(header[1:]):\n",
    "                coord_dict[hdr] = coord_arr[: len(files), i + 1].astype(np.float64)\n",
    "\n",
    "        if len(files) == 0:\n",
    "            # If no files found up to this point, return None\n",
    "            return None\n",
    "\n",
    "        return files, coord_dict\n",
    "\n",
    "    def load_single(self, file_path, without_values=False):\n",
    "        return xr.open_dataarray(file_path, engine=\"h5netcdf\")\n",
    "\n",
    "    def infer_index(self, name):\n",
    "        # Get the scan number from file name\n",
    "        try:\n",
    "            scan_num: str = re.match(r\".*?(\\d{3})(?:_S\\d{3})?\", name).group(1)\n",
    "        except (AttributeError, IndexError):\n",
    "            return None, None\n",
    "\n",
    "        if scan_num.isdigit():\n",
    "            # The second return value, a dictionary, is reserved for more complex\n",
    "            # setups. See tips below for a brief explanation.\n",
    "            return int(scan_num), {}\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are more class attributes and methods that can be inherited or\n",
    "overridden to customize the loader's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erlab.io.loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `example` loader has been registered. Let's test the loader by\n",
    "loading and plotting some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erlab.io.set_loader(\"example\")\n",
    "erlab.io.set_data_dir(tmp_dir.name)\n",
    "erlab.io.load(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erlab.io.load(5).qplot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Brilliant! We now have a working loader for our hypothetical setup. However, we can't\n",
    "use :func:`erlab.io.summarize` with our loader yet.\n",
    "\n",
    "To enable summary generation, we need to implement two attributes and one method:\n",
    "\n",
    "- :attr:`formatters <erlab.io.dataloader.LoaderBase.formatters>`: A dictionary that maps\n",
    "  attribute or coordinate names in the data to functions that convert the coordinate or\n",
    "  attribute value into a human-readable form.\n",
    "\n",
    "- :attr:`summary_attrs <erlab.io.dataloader.LoaderBase.summary_attrs>`: A dictionary\n",
    "  that maps summary column names to attribute or coordinate names in the data. A\n",
    "  callable can also be used to generate entries for attributes that are not directly\n",
    "  present in the data. \n",
    "\n",
    "- :meth:`files_for_summary <erlab.io.dataloader.LoaderBase.files_for_summary>`: A method\n",
    "  that takes a path to a directory and returns a list of file paths in the directory\n",
    "  that are associated with the loader. \n",
    "\n",
    "You can also choose to implement the following attribute to further customize the summary:\n",
    "\n",
    "- :attr:`summary_sort <erlab.io.dataloader.LoaderBase.summary_sort>`: A string that determines the\n",
    "  column name to sort the summary table with. If not provided, the table will respect\n",
    "  the order of the files returned by :meth:`files_for_summary\n",
    "  <erlab.io.dataloader.LoaderBase.files_for_summary>`.\n",
    "\n",
    "To improve the performance of summary generation, you can optionally implement\n",
    ":meth:`load_single <erlab.io.dataloader.LoaderBase.load_single>` to utilize the\n",
    "``without_values`` argument. If it is True, it means that the values in the\n",
    "returned data of :meth:`load_single <erlab.io.dataloader.LoaderBase.load_single>` will\n",
    "not be accessed, so you can return the data with its values set to arbitrary numbers.\n",
    "This is useful when only the metadata is needed for the summary. An example of this will\n",
    "be shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_polarization(val) -> str:\n",
    "    val = round(float(val))\n",
    "    return {0: \"LH\", 2: \"LV\", -1: \"RC\", 1: \"LC\"}.get(val, str(val))\n",
    "\n",
    "\n",
    "def _parse_time(darr: xr.DataArray) -> datetime.datetime:\n",
    "    return datetime.datetime.strptime(\n",
    "        f\"{darr.attrs['Date']} {darr.attrs['Time']}\",\n",
    "        \"%d/%m/%Y %I:%M:%S %p\",\n",
    "    )\n",
    "\n",
    "\n",
    "def _determine_kind(darr: xr.DataArray) -> str:\n",
    "    if \"scan_type\" in darr.attrs and darr.attrs[\"scan_type\"] == \"live\":\n",
    "        return \"LP\" if \"beta\" in darr.dims else \"LXY\"\n",
    "\n",
    "    data_type = \"xps\"\n",
    "    if \"alpha\" in darr.dims:\n",
    "        data_type = \"cut\"\n",
    "    if \"beta\" in darr.dims:\n",
    "        data_type = \"map\"\n",
    "    if \"hv\" in darr.dims:\n",
    "        data_type = \"hvdep\"\n",
    "    return data_type\n",
    "\n",
    "\n",
    "class ExampleLoaderComplete(ExampleLoader):\n",
    "    name = \"example_complete\"\n",
    "    aliases = [\"ExC\"]\n",
    "\n",
    "    formatters = {\n",
    "        \"polarization\": _format_polarization,\n",
    "        \"LensMode\": lambda x: x.replace(\"Angular\", \"A\"),\n",
    "    }\n",
    "\n",
    "    summary_attrs = {\n",
    "        \"Time\": _parse_time,\n",
    "        \"Type\": _determine_kind,\n",
    "        \"Lens Mode\": \"LensMode\",\n",
    "        \"Scan Type\": \"SpectrumType\",\n",
    "        \"T(K)\": \"sample_temp\",\n",
    "        \"Pass E\": \"PassEnergy\",\n",
    "        \"Polarization\": \"polarization\",\n",
    "        \"hv\": \"hv\",\n",
    "        \"x\": \"x\",\n",
    "        \"y\": \"y\",\n",
    "        \"z\": \"z\",\n",
    "        \"polar\": \"beta\",\n",
    "        \"tilt\": \"xi\",\n",
    "        \"azi\": \"delta\",\n",
    "    }\n",
    "\n",
    "    summary_sort = \"Time\"\n",
    "\n",
    "    def load_single(self, file_path, without_values=False):\n",
    "        darr = xr.open_dataarray(file_path, engine=\"h5netcdf\")\n",
    "\n",
    "        if without_values:\n",
    "            # Prevent loading values into memory\n",
    "            return xr.DataArray(\n",
    "                np.zeros(darr.shape, darr.dtype),\n",
    "                coords=darr.coords,\n",
    "                dims=darr.dims,\n",
    "                attrs=darr.attrs,\n",
    "            )\n",
    "\n",
    "        return darr\n",
    "\n",
    "    def files_for_summary(self, data_dir):\n",
    "        return erlab.io.utils.get_files(data_dir, extensions=[\".h5\"])\n",
    "\n",
    "\n",
    "erlab.io.loaders"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. _summary example:\n",
    "\n",
    "Let's see how the resulting summary looks like.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    - If `ipywidgets <https://github.com/jupyter-widgets/ipywidgets>`_ is not installed, only the DataFrame will be displayed.\n",
    "    - If you are viewing this documentation online, the summary will not be interactive. Run the code locally to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erlab.io.set_loader(\"example_complete\")\n",
    "erlab.io.summarize()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Each cell in the summary table is formatted with :meth:`formatter\n",
    "<erlab.io.dataloader.LoaderBase.formatter>` after applying the :attr:`formatters\n",
    "<erlab.io.dataloader.LoaderBase.formatters>`.\n",
    "\n",
    "Tips\n",
    "~~~~\n",
    "\n",
    "- The data loading framework is designed to be simple and flexible, but it may not cover\n",
    "  all possible setups. If you encounter a setup that cannot be loaded with the existing\n",
    "  api, please let us know by opening an issue!\n",
    "\n",
    "- Before implementing a loader, see :doc:`../generated/erlab.io.dataloader` for\n",
    "  descriptions about each attribute, and the values and types of the expected outputs.\n",
    "  The implementation of existing loaders in the :mod:`erlab.io.plugins` module is a good\n",
    "  starting point; see the `source code on github\n",
    "  <https://github.com/kmnhan/erlabpy/tree/main/src/erlab/io/plugins>`_.\n",
    "\n",
    "- If you wish to add post-processing steps that are applicable to all data loaded by\n",
    "  that loader such as fixing the sign of the binding energy coordinates, you can inherit\n",
    "  the :meth:`post_process <erlab.io.dataloader.LoaderBase.post_process>` which by\n",
    "  default handles coordinate and attribute renaming. This method is called after the\n",
    "  data is loaded and can be used to modify the data before it is returned.\n",
    "\n",
    "- For complex data structures, constructing a full path from just the sequence number \n",
    "  and the data directory can be difficult. In this case, the :meth:`identify <erlab.io.\n",
    "  dataloader.LoaderBase.identify>` can be implemented to take additional keyword\n",
    "  arguments. All keyword arguments passed to :meth:`load\n",
    "  <erlab.io.dataloader.LoaderBase. load>` are passed to :meth:`identify\n",
    "  <erlab.io.dataloader.LoaderBase.identify>`!\n",
    "\n",
    "  For instance, consider data with different prefixes like ``A_001.h5``, ``A_002.h5``,\n",
    "  ``B_001.h5``, etc. stored in the same directory. The sequence number alone is not\n",
    "  enough to construct the full path. In this case, :meth:`identify\n",
    "  <erlab.io.dataloader.LoaderBase.identify>` can be implemented to take an additional\n",
    "  ``prefix`` argument which eliminates the ambiguity. Then, ``A_001.h5`` can be loaded\n",
    "  with ``erlab.io.load(1, prefix=\"A\")``.\n",
    "\n",
    "  If there are multiple file scans in this setup like ``A_001_S001.h5``,\n",
    "  ``A_001_S002.h5``, etc., we would want to pass the ``prefix`` parameter to :meth:`load\n",
    "  <erlab.io.dataloader.LoaderBase.load>` from an identifier given as a file name. This\n",
    "  is where the second return value of :meth:`infer_index\n",
    "  <erlab.io.dataloader.LoaderBase.infer_index>` comes in handy, where you can return a\n",
    "  dictionary which is passed to :meth:`load <erlab.io.dataloader.LoaderBase.load>`.\n",
    "\n",
    "- If you have implemented a new loader or have improved an existing one, consider\n",
    "  contributing it to the ERLabPy project by opening a pull request. We are always\n",
    "  looking for new loaders to support more experimental setups! See more about\n",
    "  contributing in the :doc:`../contributing`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
